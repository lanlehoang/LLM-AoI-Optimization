[
     {
          "algorithm": "I compute a small bounded offset by normalizing each feature per-step, giving a strong negative contribution for high queue occupancy, positive contributions for being closer to destination and for higher processing rate, a small penalty for longer distance, and a very large negative value for zero-padded (missing) neighbours so the offset refines but does not overpower learned Q-values.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    distances, arc_lengths, processing_rates, queue_lengths: numpy arrays of same shape\n    returns: offsets numpy array of same shape\n    \"\"\"\n    # Ensure numpy arrays\n    d = np.asarray(distances, dtype=float)\n    a = np.asarray(arc_lengths, dtype=float)\n    p = np.asarray(processing_rates, dtype=float)\n    q = np.asarray(queue_lengths, dtype=float)\n    \n    # Prepare output\n    offsets = np.zeros_like(d, dtype=float)\n    \n    # Detect missing (zero-padded) neighbours: all features zero -> strongly negative offset\n    missing = (d == 0) & (a == 0) & (p == 0) & (q == 0)\n    \n    # Normalize features robustly (per-sample scaling)\n    eps = 1e-6\n    # For each vector, normalize to [0,1] by dividing by max (if max==0, result stays 0)\n    d_max = d.max() if d.size else 0.0\n    a_max = a.max() if a.size else 0.0\n    p_max = p.max() if p.size else 0.0\n    q_max = q.max() if q.size else 0.0\n    \n    d_norm = d / (d_max + eps)\n    a_norm = a / (a_max + eps)\n    p_norm = p / (p_max + eps)\n    q_norm = q / (q_max + eps)\n    \n    # Feature contributions (signed): higher is better\n    # - queue: negative contribution, penalize heavier for high q (exponentiate)\n    # - arc: closer (smaller arc) -> positive contribution (use 1 - a_norm)\n    # - processing: positive contribution\n    # - distance: small negative contribution\n    q_contrib = - (q_norm ** 1.25)\n    arc_contrib = (1.0 - a_norm)\n    proc_contrib = p_norm\n    dist_contrib = - d_norm\n    \n    # Weights chosen to prioritize queue avoidance, then proximity and service rate, small weight on distance\n    w_q = 0.50\n    w_arc = 0.28\n    w_proc = 0.18\n    w_dist = 0.04  # small\n    \n    raw_score = (w_q * q_contrib) + (w_arc * arc_contrib) + (w_proc * proc_contrib) + (w_dist * dist_contrib)\n    \n    # Bound the final offsets to be small compared to typical Q-values (~ +/-0.5).\n    max_offset = 0.12  # small refinement scale\n    offsets = raw_score * max_offset  # now typically in [-max_offset, +max_offset]\n    \n    # Assign strong negative for missing neighbours (so they won't be selected even if Q-values are malformed)\n    offsets = offsets.astype(float)\n    offsets[missing] = -1e3\n    \n    return offsets",
          "objective": 1.5176,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.6251895413182893,
               "avg_dropped_ratio": 0.05120481927710843
          }
     },
     {
          "algorithm": "Combine normalized cues (queue congestion penalty, proximity to destination, processing speed and propagation distance) into a small, capped offset that nudges Q-values toward low-queue, close-to-destination, high-service, and short-propagation neighbors without overpowering the learned Qs.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    Inputs:\n      distances, arc_lengths, processing_rates, queue_lengths: numpy arrays of same shape\n    Output:\n      offsets: numpy array of same shape\n    \"\"\"\n    eps = 1e-8\n    distances = np.asarray(distances, dtype=float)\n    arc_lengths = np.asarray(arc_lengths, dtype=float)\n    processing_rates = np.asarray(processing_rates, dtype=float)\n    queue_lengths = np.asarray(queue_lengths, dtype=float)\n\n    # Normalize each feature to [0,1] robustly (constant arrays -> zeros)\n    def norm(x):\n        mn = np.nanmin(x)\n        mx = np.nanmax(x)\n        d = mx - mn\n        if d <= eps:\n            return np.zeros_like(x, dtype=float)\n        return (x - mn) / (d + eps)\n\n    dist_n = norm(distances)          # larger -> worse\n    arc_n = norm(arc_lengths)         # larger arc -> farther from dest\n    proc_n = norm(processing_rates)   # larger -> better\n    queue_n = norm(queue_lengths)     # larger -> worse\n\n    # Derived scores: prefer small arc (closer to destination), high processing rate, low queue\n    arc_score = 1.0 - arc_n           # 1 is best (closest)\n    queue_penalty = queue_n**1.5      # amplify congestion effect slightly\n\n    # Weights chosen to nudge agent without overpowering; will be capped later\n    w_queue = -0.28\n    w_arc   =  0.12\n    w_proc  =  0.08\n    w_dist  = -0.04\n\n    offsets = (w_queue * queue_penalty) + (w_arc * arc_score) + (w_proc * proc_n) + (w_dist * dist_n)\n\n    # Cap magnitude so offsets refine (not overpower) learned Q-values\n    max_mag = 0.25\n    offsets = np.clip(offsets, -max_mag, max_mag)\n\n    return offsets",
          "objective": 1.4706,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.649267403762899,
               "avg_dropped_ratio": 0.045180722891566265
          }
     },
     {
          "algorithm": "Combine normalized feature scores into a small, bounded offset per neighbour: penalize high queue lengths and long distances, reward short arc_length (closer to destination) and high processing_rate, and clip to keep offsets from overpowering the learned Q-values.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    Inputs:\n      - distances, arc_lengths, processing_rates, queue_lengths: numpy arrays of same shape\n    Output:\n      - offsets: numpy array of same shape\n    \"\"\"\n    d = np.asarray(distances, dtype=float)\n    a = np.asarray(arc_lengths, dtype=float)\n    p = np.asarray(processing_rates, dtype=float)\n    q = np.asarray(queue_lengths, dtype=float)\n\n    eps = 1e-8\n\n    def minmax_norm(x):\n        if x.size == 0:\n            return x\n        xmin = np.nanmin(x)\n        xmax = np.nanmax(x)\n        if np.isclose(xmax, xmin):\n            return np.zeros_like(x, dtype=float)\n        return (x - xmin) / (xmax - xmin)\n\n    # Normalized features in [0,1]\n    d_norm = minmax_norm(d)            # larger = farther (worse)\n    a_norm = minmax_norm(a)            # larger = farther along arc (worse)\n    # prefer smaller arc_length -> inverse preference\n    a_pref = 1.0 - a_norm\n    p_norm = minmax_norm(p)            # larger = faster service (better)\n    q_norm = minmax_norm(q)            # larger = more queued (worse)\n\n    # Emphasize queue nonlinearly (heavier penalty for higher queues)\n    q_score = q_norm ** 1.2\n\n    # Weights chosen to produce modest offsets that refine but don't dominate Q-values\n    w_q = -0.20   # penalty for queue congestion\n    w_a = 0.09    # reward for being closer to destination\n    w_p = 0.06    # reward for higher processing rate\n    w_d = -0.03   # small penalty for larger propagation distance\n\n    offsets = w_q * q_score + w_a * a_pref + w_p * p_norm + w_d * d_norm\n\n    # Clip to a small range so offsets refine the agent's Q-values without overpowering them\n    offsets = np.clip(offsets, -0.25, 0.12)\n\n    return offsets",
          "objective": 1.4681,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.639074252125732,
               "avg_dropped_ratio": 0.06174698795180723
          }
     },
     {
          "algorithm": "Combine normalized, bounded scores that reward short arc distances, high processing rates and short physical distance while penalizing high queue occupancy, with detection of zero-padded (missing) neighbours set to -inf so offsets refine but do not overpower learned Q-values.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    Inputs:\n        distances, arc_lengths, processing_rates, queue_lengths: NumPy arrays of same shape\n    Output:\n        offsets: NumPy array of same shape (float), offsets to add to agent Q-values\n                 Missing neighbours (all-zero features) get offset -np.inf\n    \"\"\"\n    # Ensure numpy arrays\n    distances = np.asarray(distances, dtype=float)\n    arc_lengths = np.asarray(arc_lengths, dtype=float)\n    processing_rates = np.asarray(processing_rates, dtype=float)\n    queue_lengths = np.asarray(queue_lengths, dtype=float)\n\n    shape = distances.shape\n    flat = lambda x: x.reshape(-1)\n\n    d = flat(distances)\n    a = flat(arc_lengths)\n    p = flat(processing_rates)\n    q = flat(queue_lengths)\n\n    # Detect missing neighbours: all features exactly zero (zero-padding)\n    missing = (d == 0) & (a == 0) & (p == 0) & (q == 0)\n\n    eps = 1e-8\n\n    def norm_positive(x, mask_valid):\n        # Normalize x over valid entries to [0,1]; invalid entries get 0\n        if np.any(mask_valid):\n            xm = x[mask_valid]\n            xmin = xm.min()\n            xmax = xm.max()\n            if xmax - xmin < eps:\n                out = np.zeros_like(x)\n                out[mask_valid] = 0.0\n                return out\n            out = (x - xmin) / (xmax - xmin + eps)\n            out[~mask_valid] = 0.0\n            return out\n        else:\n            return np.zeros_like(x)\n\n    valid = ~missing\n\n    # Normalizations (only using valid entries to compute min/max)\n    dist_norm = norm_positive(d, valid)        # higher = farther\n    arc_norm  = norm_positive(a, valid)        # higher = farther (worse)\n    proc_norm = norm_positive(p, valid)        # higher = better\n    q_norm    = norm_positive(q, valid)        # higher = worse\n\n    # Convert to \"goodness\" where larger is better\n    dist_good = 1.0 - dist_norm   # shorter distance -> higher\n    arc_good  = 1.0 - arc_norm    # closer to destination -> higher\n    proc_good = proc_norm         # higher processing -> higher\n    # Queue: low queue is better -> use penalizing nonlinearity\n    q_bad = q_norm                # higher means worse\n\n    # Weights chosen to refine learned Q-values without overpowering them.\n    w_arc = 0.06\n    w_proc = 0.05\n    w_dist = 0.03\n    w_q = 0.12\n\n    # Nonlinear increase of penalty with queue occupancy\n    q_penalty = (q_bad ** 1.5)\n\n    offsets_flat = (w_arc * arc_good) + (w_proc * proc_good) + (w_dist * dist_good) - (w_q * q_penalty)\n\n    # Clip to a small range so we do not overpower learned Q-values\n    offsets_flat = np.clip(offsets_flat, -0.20, 0.20)\n\n    # Set missing neighbours to -inf so they are never selected (matches -inf Q-values)\n    offsets_flat[missing] = -np.inf\n\n    offsets = offsets_flat.reshape(shape).astype(float)\n    return offsets",
          "objective": 1.4428,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.65446266042459,
               "avg_dropped_ratio": 0.05572289156626506
          }
     }
]