{
     "algorithm": "Compute a small, bounded heuristic offset by combining (positive) proximity-to-destination and processing-rate signals with (negative) queue-congestion and propagation-delay penalties, normalized per-sample so offsets refine but do not overwhelm learned Q-values.",
     "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    Inputs: distances, arc_lengths, processing_rates, queue_lengths (numpy arrays, same shape)\n    Output: offsets (numpy array, same shape)\n    \"\"\"\n    distances = np.asarray(distances, dtype=np.float64)\n    arc_lengths = np.asarray(arc_lengths, dtype=np.float64)\n    processing_rates = np.asarray(processing_rates, dtype=np.float64)\n    queue_lengths = np.asarray(queue_lengths, dtype=np.float64)\n    \n    # Prevent division by zero in normalization\n    eps = 1e-8\n    \n    # Mask invalid / padded neighbours (all-zero feature rows)\n    invalid = (distances == 0) & (arc_lengths == 0) & (processing_rates == 0) & (queue_lengths == 0)\n    \n    # 1) Proximity to destination: use inverse arc length, give a stronger bonus for very small arc lengths (including zero)\n    inv_arc = 1.0 / (arc_lengths + eps)\n    # Normalize to [0,1]\n    max_inv_arc = np.max(inv_arc) if np.max(inv_arc) > 0 else 1.0\n    arc_score = inv_arc / (max_inv_arc + eps)\n    \n    # 2) Processing rate: higher is better\n    max_proc = np.max(processing_rates) if np.max(processing_rates) > 0 else 1.0\n    proc_score = processing_rates / (max_proc + eps)\n    \n    # 3) Queue congestion: higher is worse; use a slightly superlinear penalty so high queues are penalized more\n    max_queue = np.max(queue_lengths)\n    # If all queues zero, avoid division by zero; use denom >=1\n    denom_q = max(1.0, max_queue)\n    q_norm = queue_lengths / (denom_q + eps)\n    q_score = np.power(q_norm, 1.2)  # sharpen penalty for larger queues\n    \n    # 4) Distance penalty (propagation delay): longer distance slightly worse\n    max_dist = np.max(distances) if np.max(distances) > 0 else 1.0\n    dist_score = distances / (max_dist + eps)\n    \n    # Weights chosen so offsets are modest (do not overwhelm learned Q-values)\n    w_arc = 0.12    # positive weight for closeness to destination\n    w_proc = 0.08   # positive weight for higher processing rate\n    w_queue = 0.14  # negative weight for queue congestion\n    w_dist = 0.02   # negative weight for propagation distance\n    \n    offsets = (w_arc * arc_score) + (w_proc * proc_score) - (w_queue * q_score) - (w_dist * dist_score)\n    \n    # Encourage direct delivery (arc_length == 0) a bit more (explicit boost) but keep within bounds\n    direct_mask = (arc_lengths == 0) & (~invalid)\n    offsets[direct_mask] += 0.04\n    \n    # Clip offsets to a small range so they refine but don't dominate learned Q-values\n    offsets = np.clip(offsets, -0.16, 0.16)\n    \n    # Set offsets for invalid/padded neighbours to zero (Q-agent is typically -inf there anyway)\n    offsets[invalid] = 0.0\n    \n    return offsets",
     "objective": 1.5415,
     "other_inf": null,
     "eval_metrics": {
          "avg_aoi": 0.6008486373997836,
          "avg_dropped_ratio": 0.07379518072289157
     }
}