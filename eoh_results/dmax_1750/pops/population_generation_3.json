[
     {
          "algorithm": "Compute a small, bounded heuristic offset by combining (positive) proximity-to-destination and processing-rate signals with (negative) queue-congestion and propagation-delay penalties, normalized per-sample so offsets refine but do not overwhelm learned Q-values.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    Inputs: distances, arc_lengths, processing_rates, queue_lengths (numpy arrays, same shape)\n    Output: offsets (numpy array, same shape)\n    \"\"\"\n    distances = np.asarray(distances, dtype=np.float64)\n    arc_lengths = np.asarray(arc_lengths, dtype=np.float64)\n    processing_rates = np.asarray(processing_rates, dtype=np.float64)\n    queue_lengths = np.asarray(queue_lengths, dtype=np.float64)\n    \n    # Prevent division by zero in normalization\n    eps = 1e-8\n    \n    # Mask invalid / padded neighbours (all-zero feature rows)\n    invalid = (distances == 0) & (arc_lengths == 0) & (processing_rates == 0) & (queue_lengths == 0)\n    \n    # 1) Proximity to destination: use inverse arc length, give a stronger bonus for very small arc lengths (including zero)\n    inv_arc = 1.0 / (arc_lengths + eps)\n    # Normalize to [0,1]\n    max_inv_arc = np.max(inv_arc) if np.max(inv_arc) > 0 else 1.0\n    arc_score = inv_arc / (max_inv_arc + eps)\n    \n    # 2) Processing rate: higher is better\n    max_proc = np.max(processing_rates) if np.max(processing_rates) > 0 else 1.0\n    proc_score = processing_rates / (max_proc + eps)\n    \n    # 3) Queue congestion: higher is worse; use a slightly superlinear penalty so high queues are penalized more\n    max_queue = np.max(queue_lengths)\n    # If all queues zero, avoid division by zero; use denom >=1\n    denom_q = max(1.0, max_queue)\n    q_norm = queue_lengths / (denom_q + eps)\n    q_score = np.power(q_norm, 1.2)  # sharpen penalty for larger queues\n    \n    # 4) Distance penalty (propagation delay): longer distance slightly worse\n    max_dist = np.max(distances) if np.max(distances) > 0 else 1.0\n    dist_score = distances / (max_dist + eps)\n    \n    # Weights chosen so offsets are modest (do not overwhelm learned Q-values)\n    w_arc = 0.12    # positive weight for closeness to destination\n    w_proc = 0.08   # positive weight for higher processing rate\n    w_queue = 0.14  # negative weight for queue congestion\n    w_dist = 0.02   # negative weight for propagation distance\n    \n    offsets = (w_arc * arc_score) + (w_proc * proc_score) - (w_queue * q_score) - (w_dist * dist_score)\n    \n    # Encourage direct delivery (arc_length == 0) a bit more (explicit boost) but keep within bounds\n    direct_mask = (arc_lengths == 0) & (~invalid)\n    offsets[direct_mask] += 0.04\n    \n    # Clip offsets to a small range so they refine but don't dominate learned Q-values\n    offsets = np.clip(offsets, -0.16, 0.16)\n    \n    # Set offsets for invalid/padded neighbours to zero (Q-agent is typically -inf there anyway)\n    offsets[invalid] = 0.0\n    \n    return offsets",
          "objective": 1.5415,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.6008486373997836,
               "avg_dropped_ratio": 0.07379518072289157
          }
     },
     {
          "algorithm": "A normalized, bounded heuristic that blends an inverse-logarithmic proximity-to-destination score, a log-scaled processing-rate bonus, a superlinear queue congestion penalty, and a distance penalty using adjusted weights so offsets modestly refine but do not dominate learned Q-values.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    Inputs: distances, arc_lengths, processing_rates, queue_lengths (numpy arrays, same shape)\n    Output: offsets (numpy array, same shape)\n    \"\"\"\n    distances = np.asarray(distances, dtype=np.float64)\n    arc_lengths = np.asarray(arc_lengths, dtype=np.float64)\n    processing_rates = np.asarray(processing_rates, dtype=np.float64)\n    queue_lengths = np.asarray(queue_lengths, dtype=np.float64)\n\n    eps = 1e-8\n\n    # Mask invalid / padded neighbours (all-zero feature rows)\n    invalid = (distances == 0) & (arc_lengths == 0) & (processing_rates == 0) & (queue_lengths == 0)\n\n    # 1) Proximity to destination: inverse-log scaling to reduce dominance of very large arc lengths\n    inv_log_arc = 1.0 / (1.0 + np.log1p(arc_lengths + eps))\n    max_inv_log_arc = np.max(inv_log_arc) if np.max(inv_log_arc) > 0 else 1.0\n    arc_score = inv_log_arc / (max_inv_log_arc + eps)\n\n    # 2) Processing rate: log-scaled to compress large rate differences\n    proc_log = np.log1p(processing_rates)\n    max_proc_log = np.max(proc_log) if np.max(proc_log) > 0 else 1.0\n    proc_score = proc_log / (max_proc_log + eps)\n\n    # 3) Queue congestion: normalized then sharpened with superlinear exponent to penalize high queues\n    max_queue = np.max(queue_lengths)\n    denom_q = max(1.0, max_queue)\n    q_norm = queue_lengths / (denom_q + eps)\n    q_score = np.power(q_norm, 1.6)  # stronger penalty for larger queues\n\n    # 4) Distance penalty (propagation delay): normalized linear penalty\n    max_dist = np.max(distances) if np.max(distances) > 0 else 1.0\n    dist_score = distances / (max_dist + eps)\n\n    # Weights chosen to provide modest adjustments (different from previous settings)\n    w_arc = 0.10    # positive weight for closeness to destination (reduced slightly)\n    w_proc = 0.12   # positive weight for higher processing rate (increased)\n    w_queue = 0.20  # negative weight for queue congestion (increased)\n    w_dist = 0.03   # negative weight for propagation distance (increased a bit)\n\n    offsets = (w_arc * arc_score) + (w_proc * proc_score) - (w_queue * q_score) - (w_dist * dist_score)\n\n    # Extra encouragement for direct delivery (arc_length == 0) but slightly larger than before\n    direct_mask = (arc_lengths == 0) & (~invalid)\n    offsets[direct_mask] += 0.05\n\n    # Clip offsets to a small range so they refine but don't dominate learned Q-values (narrower range)\n    offsets = np.clip(offsets, -0.12, 0.12)\n\n    # Ensure invalid/padded neighbours have zero offset\n    offsets[invalid] = 0.0\n\n    return offsets",
          "objective": 1.5318,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.605626708584327,
               "avg_dropped_ratio": 0.07228915662650602
          }
     },
     {
          "algorithm": "Combine normalized, non-linear transforms of proximity (inverse arc via exponential), processing power (tanh), queue congestion (exponential penalty) and propagation delay (exponential penalty) into a small bounded offset that boosts likely-good hops and penalizes congested/long-delay hops while leaving padded/invalid neighbours at zero.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    distances = np.asarray(distances, dtype=np.float64)\n    arc_lengths = np.asarray(arc_lengths, dtype=np.float64)\n    processing_rates = np.asarray(processing_rates, dtype=np.float64)\n    queue_lengths = np.asarray(queue_lengths, dtype=np.float64)\n    \n    eps = 1e-8\n    \n    # Invalid (padded) neighbours: all features zero\n    invalid = (distances == 0) & (arc_lengths == 0) & (processing_rates == 0) & (queue_lengths == 0)\n    valid = ~invalid\n    \n    offsets = np.zeros_like(distances, dtype=np.float64)\n    if not np.any(valid):\n        return offsets  # all invalid, return zeros\n    \n    # Scales computed over valid entries, with sensible fallbacks\n    arc_med = np.median(arc_lengths[valid]) if np.any(valid) else 1.0\n    arc_scale = max(arc_med, 1.0)\n    \n    proc_mean = np.mean(processing_rates[valid]) if np.any(valid) else 1.0\n    proc_scale = max(proc_mean, 1.0)\n    \n    queue_mean = np.mean(queue_lengths[valid]) if np.any(valid) else 1.0\n    queue_scale = max(queue_mean, 1.0)\n    \n    dist_mean = np.mean(distances[valid]) if np.any(valid) else 1.0\n    dist_scale = max(dist_mean, 1.0)\n    \n    # 1) Proximity: exponential decay of arc length -> higher when close; normalize to [0,1]\n    prox_raw = np.exp(-arc_lengths / (arc_scale + eps))\n    prox_max = np.max(prox_raw[valid]) if np.any(valid) and np.max(prox_raw[valid]) > 0 else 1.0\n    prox_score = prox_raw / (prox_max + eps)\n    \n    # 2) Processing: smooth saturating benefit via tanh, mapped to [0,1]\n    proc_scaled = processing_rates / (proc_scale + eps)\n    proc_score = (np.tanh(proc_scaled) + 1.0) * 0.5\n    \n    # 3) Queue congestion: sublinear->superlinear penalty using 1 - exp(- (q/scale)^p)\n    q_ratio = queue_lengths / (queue_scale + eps)\n    queue_score = 1.0 - np.exp(-np.power(q_ratio, 1.4))\n    # ensure in [0,1]\n    queue_score = np.clip(queue_score, 0.0, 1.0)\n    \n    # 4) Distance (propagation) penalty: gentle exponential penalty normalized\n    dist_raw = 1.0 - np.exp(-distances / (dist_scale + eps))\n    dist_max = np.max(dist_raw[valid]) if np.any(valid) and np.max(dist_raw[valid]) > 0 else 1.0\n    dist_score = dist_raw / (dist_max + eps)\n    \n    # Combine with modest weights so offsets refine agent Q-values\n    w_prox = 0.12\n    w_proc = 0.07\n    w_queue = 0.16\n    w_dist = 0.03\n    \n    offsets = (w_prox * prox_score) + (w_proc * proc_score) - (w_queue * queue_score) - (w_dist * dist_score)\n    \n    # Extra small incentive for direct delivery (arc_length == 0) for valid neighbours\n    direct = (arc_lengths == 0) & valid\n    offsets[direct] += 0.045\n    \n    # Clip to a small bounded range so offsets refine but don't dominate learned Q-values\n    offsets = np.clip(offsets, -0.14, 0.14)\n    \n    # Zero out invalid entries explicitly\n    offsets[invalid] = 0.0\n    \n    return offsets",
          "objective": 1.5281,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.6002005585763402,
               "avg_dropped_ratio": 0.08283132530120482
          }
     },
     {
          "algorithm": "Combine a harmonic-mean \"goodness\" of processing rate and proximity, multiplicatively gated by a nonlinear queue-penalty and distance damping, then squash to a small bounded offset so the heuristic refines but does not overpower the agent.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    Inputs:\n      distances, arc_lengths, processing_rates, queue_lengths: numpy arrays of same shape\n    Output:\n      offsets: numpy array of same shape with additive offsets for Q-values\n    \"\"\"\n    distances = np.asarray(distances, dtype=np.float64)\n    arc_lengths = np.asarray(arc_lengths, dtype=np.float64)\n    processing_rates = np.asarray(processing_rates, dtype=np.float64)\n    queue_lengths = np.asarray(queue_lengths, dtype=np.float64)\n\n    eps = 1e-8\n\n    # Identify padded/invalid neighbours (all-zero feature vectors)\n    invalid = (distances == 0) & (arc_lengths == 0) & (processing_rates == 0) & (queue_lengths == 0)\n\n    # Normalize features to comparable scales (0..1 where higher is better for proc/closeness)\n    max_arc = arc_lengths.max() if arc_lengths.max() > 0 else 1.0\n    arc_norm = arc_lengths / (max_arc + eps)\n    closeness = 1.0 - np.clip(arc_norm, 0.0, 1.0)   # higher when closer to destination\n\n    max_proc = processing_rates.max() if processing_rates.max() > 0 else 1.0\n    proc_norm = np.clip(processing_rates / (max_proc + eps), 0.0, 1.0)\n\n    # Queue normalized against a reasonable cap so a few large queues don't shrink everything\n    q_cap = max(queue_lengths.max(), 8.0)\n    queue_norm = np.clip(queue_lengths / (q_cap + eps), 0.0, 1.0)\n\n    max_dist = distances.max() if distances.max() > 0 else 1.0\n    dist_norm = np.clip(distances / (max_dist + eps), 0.0, 1.0)\n\n    # 1) Harmonic-like combination of positive signals (favors neighbours that are both fast and close)\n    #    Using harmonic mean style reduces the score if either proc or closeness is low.\n    pos = (2.0 * proc_norm * closeness) / (proc_norm + closeness + eps)\n\n    # 2) Nonlinear queue gate: small queues barely reduce score, large queues strongly reduce (and can invert)\n    queue_gate = 1.0 - np.power(queue_norm, 1.7)   # in ( -something, 1 ], lower for large queues\n\n    # 3) Distance damping: long propagation distance reduces the effective score smoothly\n    dist_damp = 1.0 / (1.0 + 1.6 * dist_norm)     # in ( ~0.38, 1 ]\n\n    # Combine multiplicatively (different form from linear weighted sums)\n    raw_score = pos * queue_gate * dist_damp\n\n    # Add an explicit small penalty proportional to queue (ensures strong congestion is discouraged)\n    raw_score = raw_score - 0.25 * queue_norm\n\n    # Scale and squash to ensure offsets are modest refinements\n    # Use tanh to keep smooth, then scale to final bounded range\n    offsets = np.tanh(raw_score * 1.6) * 0.18  # final values approximately in [-0.18, 0.18]\n\n    # Ensure padded/invalid neighbours get zero offset (agent Q-values are typically -inf there)\n    offsets[invalid] = 0.0\n\n    return offsets",
          "objective": 1.5181,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.6111109804524129,
               "avg_dropped_ratio": 0.07228915662650602
          }
     }
]