[
     {
          "algorithm": "Compute a small, bounded heuristic offset by combining (positive) proximity-to-destination and processing-rate signals with (negative) queue-congestion and propagation-delay penalties, normalized per-sample so offsets refine but do not overwhelm learned Q-values.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    Inputs: distances, arc_lengths, processing_rates, queue_lengths (numpy arrays, same shape)\n    Output: offsets (numpy array, same shape)\n    \"\"\"\n    distances = np.asarray(distances, dtype=np.float64)\n    arc_lengths = np.asarray(arc_lengths, dtype=np.float64)\n    processing_rates = np.asarray(processing_rates, dtype=np.float64)\n    queue_lengths = np.asarray(queue_lengths, dtype=np.float64)\n    \n    # Prevent division by zero in normalization\n    eps = 1e-8\n    \n    # Mask invalid / padded neighbours (all-zero feature rows)\n    invalid = (distances == 0) & (arc_lengths == 0) & (processing_rates == 0) & (queue_lengths == 0)\n    \n    # 1) Proximity to destination: use inverse arc length, give a stronger bonus for very small arc lengths (including zero)\n    inv_arc = 1.0 / (arc_lengths + eps)\n    # Normalize to [0,1]\n    max_inv_arc = np.max(inv_arc) if np.max(inv_arc) > 0 else 1.0\n    arc_score = inv_arc / (max_inv_arc + eps)\n    \n    # 2) Processing rate: higher is better\n    max_proc = np.max(processing_rates) if np.max(processing_rates) > 0 else 1.0\n    proc_score = processing_rates / (max_proc + eps)\n    \n    # 3) Queue congestion: higher is worse; use a slightly superlinear penalty so high queues are penalized more\n    max_queue = np.max(queue_lengths)\n    # If all queues zero, avoid division by zero; use denom >=1\n    denom_q = max(1.0, max_queue)\n    q_norm = queue_lengths / (denom_q + eps)\n    q_score = np.power(q_norm, 1.2)  # sharpen penalty for larger queues\n    \n    # 4) Distance penalty (propagation delay): longer distance slightly worse\n    max_dist = np.max(distances) if np.max(distances) > 0 else 1.0\n    dist_score = distances / (max_dist + eps)\n    \n    # Weights chosen so offsets are modest (do not overwhelm learned Q-values)\n    w_arc = 0.12    # positive weight for closeness to destination\n    w_proc = 0.08   # positive weight for higher processing rate\n    w_queue = 0.14  # negative weight for queue congestion\n    w_dist = 0.02   # negative weight for propagation distance\n    \n    offsets = (w_arc * arc_score) + (w_proc * proc_score) - (w_queue * q_score) - (w_dist * dist_score)\n    \n    # Encourage direct delivery (arc_length == 0) a bit more (explicit boost) but keep within bounds\n    direct_mask = (arc_lengths == 0) & (~invalid)\n    offsets[direct_mask] += 0.04\n    \n    # Clip offsets to a small range so they refine but don't dominate learned Q-values\n    offsets = np.clip(offsets, -0.16, 0.16)\n    \n    # Set offsets for invalid/padded neighbours to zero (Q-agent is typically -inf there anyway)\n    offsets[invalid] = 0.0\n    \n    return offsets",
          "objective": 1.5415,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.6008486373997836,
               "avg_dropped_ratio": 0.07379518072289157
          }
     },
     {
          "algorithm": "Combine normalized features into a small additive offset: reward low arc_length and high processing_rate, penalize high queue_length and long distance, and strongly negative-mask padded/invalid neighbours.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    Inputs:\n      distances, arc_lengths, processing_rates, queue_lengths: numpy arrays of same shape\n    Output:\n      offsets: numpy array of same shape with additive offsets for Q-values\n    \"\"\"\n    distances = np.asarray(distances, dtype=float)\n    arc_lengths = np.asarray(arc_lengths, dtype=float)\n    processing_rates = np.asarray(processing_rates, dtype=float)\n    queue_lengths = np.asarray(queue_lengths, dtype=float)\n    \n    # Prepare output\n    offsets = np.zeros_like(distances, dtype=float)\n    \n    # Identify padded/invalid neighbours (all-zero feature vectors)\n    invalid = (distances == 0) & (arc_lengths == 0) & (processing_rates == 0) & (queue_lengths == 0)\n    \n    eps = 1e-8\n    \n    # Normalized scores in [0,1] (higher = better), or negative for congestion\n    max_arc = max(arc_lengths.max(), eps)\n    arc_score = 1.0 - (arc_lengths / (max_arc + eps))            # lower arc_length -> higher score\n    \n    max_proc = max(processing_rates.max(), eps)\n    proc_score = processing_rates / (max_proc + eps)             # higher processing rate -> higher score\n    \n    # Queue penalty: higher queue -> stronger negative; cap denominator to avoid tiny scale\n    max_q = queue_lengths.max()\n    cap_q = max(max_q, 10.0)                                     # treat typical max queue ~10 for normalization\n    queue_penalty = np.minimum(queue_lengths / (cap_q + eps), 1.0)\n    queue_score = -queue_penalty                                 # negative: more queue -> more negative\n    \n    max_dist = max(distances.max(), eps)\n    dist_penalty = distances / (max_dist + eps)\n    dist_score = -dist_penalty                                   # longer distance -> slight negative\n    \n    # Weights chosen to refine learned Q-values (small magnitudes)\n    w_arc = 0.18\n    w_proc = 0.12\n    w_queue = 0.35\n    w_dist = 0.02\n    \n    raw = w_arc * arc_score + w_proc * proc_score + w_queue * queue_score + w_dist * dist_score\n    \n    # Clip offsets so they refine but do not overpower agent Q-values\n    offsets = np.clip(raw, -0.40, 0.40)\n    \n    # Strong negative for invalid/padded neighbours to avoid selection (Q-values already -inf but ensure safety)\n    offsets[invalid] = -1e3\n    \n    return offsets",
          "objective": 1.4618,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.6253531489875161,
               "avg_dropped_ratio": 0.0858433734939759
          }
     },
     {
          "algorithm": "Combine normalized features into a small bounded offset that rewards high processing rate and proximity to destination, penalizes large queues and long distances, and sets invalid (zero-padded) neighbours to a large negative value.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    Inputs:\n      - distances, arc_lengths, processing_rates, queue_lengths: numpy arrays (same shape)\n    Output:\n      - offsets: numpy array of same shape\n    \"\"\"\n    distances = np.asarray(distances, dtype=float)\n    arc_lengths = np.asarray(arc_lengths, dtype=float)\n    processing_rates = np.asarray(processing_rates, dtype=float)\n    queue_lengths = np.asarray(queue_lengths, dtype=float)\n\n    # Valid neighbour mask (zero-padded entries are invalid)\n    valid = distances > 0\n\n    # Normalizers (avoid division by zero)\n    max_proc = max(processing_rates.max(), 1.0)\n    max_arc = max(arc_lengths.max(), 1.0)\n    # add 1 to queue max so small integer queues don't saturate the norm\n    max_queue = queue_lengths.max() + 1.0\n\n    # Normalized features in [0,1]\n    proc_norm = processing_rates / max_proc\n    arc_norm = arc_lengths / max_arc\n    queue_norm = queue_lengths / max_queue\n    dist_norm = distances / max(distances.max(), 1.0)\n\n    # Weights tuned to produce small offsets that refine (not overpower) learned Q-values\n    w_proc = 0.10     # reward higher processing rate\n    w_close = 0.08    # reward being closer to destination (use 1 - arc_norm)\n    w_queue = -0.12   # penalize long queues (congestion/drop risk)\n    w_dist = -0.01    # small penalty for longer physical distance (propagation delay)\n\n    # Compose offset; keep values small and bounded\n    offsets = np.zeros_like(distances, dtype=float)\n    # base score from features\n    base = (w_proc * proc_norm) + (w_close * (1.0 - arc_norm)) + (w_queue * queue_norm) + (w_dist * dist_norm)\n    # apply only to valid neighbours\n    offsets = np.where(valid, base, -1e6)\n\n    # Clip to a reasonable range so we don't overpower Q-values (e.g., [-0.5, 0.5])\n    offsets = np.clip(offsets, -0.5, 0.5)\n\n    return offsets",
          "objective": 1.4556,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.6249155466727259,
               "avg_dropped_ratio": 0.09036144578313254
          }
     },
     {
          "algorithm": "I compute small normalized preference scores from arc length (closer better), processing rate (higher better), queue length (lower better), and distance (shorter better), combine them with conservative weights and clip to a small range so offsets refine but don't overpower learned Q-values.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    Inputs: numpy arrays of same shape:\n      distances, arc_lengths, processing_rates, queue_lengths\n    Output:\n      offsets: numpy array of same shape\n    \"\"\"\n    # ensure numpy arrays\n    distances = np.array(distances, dtype=float)\n    arc_lengths = np.array(arc_lengths, dtype=float)\n    processing_rates = np.array(processing_rates, dtype=float)\n    queue_lengths = np.array(queue_lengths, dtype=float)\n    \n    # valid mask: treat an entry as valid if at least one feature is non-zero\n    valid = (distances != 0) | (arc_lengths != 0) | (processing_rates != 0) | (queue_lengths != 0)\n    if not np.any(valid):\n        return np.zeros_like(distances, dtype=float)\n    \n    # helper to normalize to [0,1]; if constant, return 0.5 for valid entries\n    def _normalize(x, mask):\n        out = np.zeros_like(x, dtype=float)\n        if np.any(mask):\n            xm = x[mask]\n            mn = np.min(xm)\n            mx = np.max(xm)\n            if mx > mn:\n                out[mask] = (xm - mn) / (mx - mn)\n            else:\n                out[mask] = 0.5\n        return out\n\n    # normalize features over valid entries\n    dist_n = _normalize(distances, valid)          # larger => farther\n    arc_n = _normalize(arc_lengths, valid)         # larger => farther along great circle\n    proc_n = _normalize(processing_rates, valid)   # larger => better\n    q_n = _normalize(queue_lengths, valid)         # larger => worse\n\n    # derive scores (higher is better)\n    arc_score = 1.0 - arc_n          # small arc_length => high score\n    proc_score = proc_n              # high processing rate => high score\n    queue_score = q_n                # high queue => bad (will be subtracted)\n    dist_score = dist_n              # far distance => bad (will be subtracted)\n\n    # conservative weights chosen to modestly adjust Q-values (not overpower)\n    w_arc = 0.07\n    w_proc = 0.045\n    w_queue = 0.09\n    w_dist = 0.03\n\n    offsets = np.zeros_like(distances, dtype=float)\n    offsets[valid] = (w_arc * arc_score[valid]\n                      + w_proc * proc_score[valid]\n                      - w_queue * queue_score[valid]\n                      - w_dist * dist_score[valid])\n\n    # clip to small range so these are refinements, not dominant shifts\n    offsets = np.clip(offsets, -0.20, 0.20)\n\n    return offsets",
          "objective": 1.4426,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.6201237848032778,
               "avg_dropped_ratio": 0.10542168674698794
          }
     }
]