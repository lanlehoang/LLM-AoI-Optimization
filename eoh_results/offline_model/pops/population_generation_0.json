[
     {
          "algorithm": "Design a function that computes offsets based on normalized queue lengths, arc lengths, and processing rates, with distances impacting the overall delay, to refine the Q-values without overpowering them.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    # Normalize the features\n    norm_queue_lengths = queue_lengths / np.max(queue_lengths)\n    norm_arc_lengths = arc_lengths / np.max(arc_lengths)\n    norm_processing_rates = processing_rates / np.max(processing_rates)\n    \n    # Calculate delay factor from distances\n    delay_factor = distances / 3e5  # Speed of light in km/s\n    \n    # Compute offsets\n    offsets = (-norm_queue_lengths + \n               (1 - norm_arc_lengths) + \n               norm_processing_rates - \n               delay_factor)\n    \n    # Scale offsets to a similar range as the Q-values in the examples\n    offsets = offsets * 0.1\n    \n    return offsets",
          "objective": 1.4048,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.6625515771397372,
               "avg_dropped_ratio": 0.06927710843373494
          }
     },
     {
          "algorithm": "Design a function that computes offsets based on normalized queue lengths, arc lengths, and processing rates, with distances factored into the overall delay, to refine the routing decision without overpowering the learned Q-values.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    max_queue = np.max(queue_lengths)\n    min_arc = np.min(arc_lengths)\n    max_process_rate = np.max(processing_rates)\n    \n    queue_offset = -queue_lengths / max_queue if max_queue > 0 else -queue_lengths\n    arc_offset = (min_arc - arc_lengths) / min_arc if min_arc > 0 else (min_arc - arc_lengths)\n    process_offset = processing_rates / max_process_rate if max_process_rate > 0 else processing_rates\n    \n    # Adjusting for distance impact, assuming speed of light is about 3e5 km/s\n    delay_offset = -distances / (3e5)\n    \n    # Combine all offsets\n    offsets = queue_offset + arc_offset + process_offset + delay_offset\n    \n    # Normalize the final offsets to avoid overpowering the Q-values\n    offsets = (offsets - np.min(offsets)) / (np.max(offsets) - np.min(offsets))\n    \n    return offsets",
          "objective": 1.3442,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.6632858363534115,
               "avg_dropped_ratio": 0.10843373493975904
          }
     },
     {
          "algorithm": "Design a function that computes offsets based on normalized and weighted contributions from queue lengths, arc lengths, processing rates, and distances, aiming to refine the Q-values without overpowering them.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    # Normalize features\n    norm_queue_lengths = (queue_lengths - np.min(queue_lengths)) / (np.max(queue_lengths) - np.min(queue_lengths))\n    norm_arc_lengths = (np.max(arc_lengths) - arc_lengths) / (np.max(arc_lengths) - np.min(arc_lengths))\n    norm_processing_rates = (processing_rates - np.min(processing_rates)) / (np.max(processing_rates) - np.min(processing_rates))\n    norm_distances = distances / np.max(distances)\n    \n    # Compute offsets with weights\n    offsets = (-2 * norm_queue_lengths) + (1 * norm_arc_lengths) + (1 * norm_processing_rates) - (0.5 * norm_distances)\n    \n    return offsets",
          "objective": 1.2835,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.711075829492066,
               "avg_dropped_ratio": 0.08734939759036145
          }
     },
     {
          "algorithm": "Design a function that computes offsets based on normalized queue lengths, arc lengths, and processing rates, where high queue lengths negatively impact offsets, shorter arc lengths and higher processing rates positively impact offsets, and distances influence propagation delay.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    # Normalize each feature\n    norm_queue_lengths = queue_lengths / np.max(queue_lengths)\n    norm_arc_lengths = 1 - (arc_lengths / np.max(arc_lengths))\n    norm_processing_rates = processing_rates / np.max(processing_rates)\n    \n    # Compute propagation delay factor from distance\n    speed_of_light_km_per_sec = 299792.458\n    prop_delay = distances / speed_of_light_km_per_sec\n    \n    # Calculate offset\n    offsets = -2 * norm_queue_lengths + 2 * norm_arc_lengths + 2 * norm_processing_rates - prop_delay\n    \n    return offsets",
          "objective": 1.2675,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.7212265765318334,
               "avg_dropped_ratio": 0.0858433734939759
          }
     }
]