{
     "algorithm": "Combine normalized, validity-masked feature scores (favoring low queue, short arc, high processing rate, and short distance) with tuned weights, center them across available neighbours, and scale to small offsets so they refine \u2014 not overpower \u2014 learned Q-values.",
     "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    Inputs:\n      - distances, arc_lengths, processing_rates, queue_lengths : numpy arrays of same shape\n    Output:\n      - offsets : numpy array of same shape (float)\n    \"\"\"\n    # Ensure arrays\n    distances = np.asarray(distances, dtype=float)\n    arc_lengths = np.asarray(arc_lengths, dtype=float)\n    processing_rates = np.asarray(processing_rates, dtype=float)\n    queue_lengths = np.asarray(queue_lengths, dtype=float)\n    \n    # Shape check\n    if not (distances.shape == arc_lengths.shape == processing_rates.shape == queue_lengths.shape):\n        raise ValueError(\"All inputs must have the same shape\")\n    \n    # Detect padded/absent neighbours (all-zero feature rows)\n    padded = (distances == 0) & (arc_lengths == 0) & (processing_rates == 0) & (queue_lengths == 0)\n    valid = ~padded\n    offsets = np.zeros_like(distances, dtype=float)\n    \n    if not np.any(valid):\n        return offsets  # all padded -> zero offsets\n    \n    eps = 1e-8\n    \n    # Helper to compute normalized (0..1) with robust min/max over valid entries\n    def norm_positive_better(x):\n        xv = x[valid]\n        mn = np.min(xv)\n        mx = np.max(xv)\n        if mx - mn < eps:\n            return np.ones_like(x) * 0.5  # neutral when no variation\n        out = np.zeros_like(x, dtype=float)\n        out[valid] = (x[valid] - mn) / (mx - mn + eps)\n        return out\n    \n    def norm_negative_better(x):\n        # smaller values are better -> invert normalized positive-better\n        n = norm_positive_better(x)\n        return 1.0 - n\n    \n    # Compute normalized feature scores in [0,1], where higher is better\n    # - queue: smaller is better (strong effect)\n    queue_score = norm_negative_better(queue_lengths)\n    # - arc: smaller arc_length closer to destination -> better\n    arc_score = norm_negative_better(arc_lengths)\n    # - processing rate: higher is better\n    proc_score = norm_positive_better(processing_rates)\n    # - distance: smaller distance reduces propagation delay -> better (weaker effect)\n    dist_score = norm_negative_better(distances)\n    \n    # Weights (sum to 1) emphasizing queue, then arc, proc, dist\n    w_queue = 0.50\n    w_arc = 0.25\n    w_proc = 0.15\n    w_dist = 0.10\n    \n    # Combined score only for valid entries\n    combined = np.zeros_like(distances, dtype=float)\n    combined[valid] = (w_queue * queue_score[valid]\n                       + w_arc * arc_score[valid]\n                       + w_proc * proc_score[valid]\n                       + w_dist * dist_score[valid])\n    \n    # Center combined scores across valid neighbours to create relative preference\n    mean_valid = np.mean(combined[valid])\n    rel_score = np.zeros_like(combined)\n    rel_score[valid] = combined[valid] - mean_valid\n    \n    # Scale to modest offsets so we refine but don't overpower the agent Q-values\n    scale = 0.20  # typical offset magnitude (~[-0.2,0.2])\n    offsets[valid] = rel_score[valid] * scale\n    \n    # Extra nonlinear penalty for very large queues (to avoid drops) using squared term\n    # Determine a soft queue capacity baseline from observed valid queues\n    q_valid = queue_lengths[valid]\n    q_baseline = max(1.0, np.percentile(q_valid, 90))  # aggressive if queue near its 90th percentile\n    extra_penalty = np.zeros_like(offsets)\n    extra_penalty[valid] = -0.15 * ((q_valid / (q_baseline + eps)) ** 2)\n    # Apply penalty but keep offsets within reasonable bounds\n    offsets[valid] += extra_penalty[valid]\n    \n    # Clamp offsets to a safe range\n    np.clip(offsets, -0.3, 0.3, out=offsets)\n    \n    # Ensure padded entries remain zero (neutral); Q-agent should be -inf for them anyway\n    offsets[padded] = 0.0\n    \n    return offsets",
     "objective": 1.5035,
     "other_inf": null,
     "eval_metrics": {
          "avg_aoi": 0.6130308463407801,
          "avg_dropped_ratio": 0.0783132530120482
     }
}