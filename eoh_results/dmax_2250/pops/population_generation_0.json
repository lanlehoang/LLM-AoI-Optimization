[
     {
          "algorithm": "Combine normalized, validity-masked feature scores (favoring low queue, short arc, high processing rate, and short distance) with tuned weights, center them across available neighbours, and scale to small offsets so they refine \u2014 not overpower \u2014 learned Q-values.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    Inputs:\n      - distances, arc_lengths, processing_rates, queue_lengths : numpy arrays of same shape\n    Output:\n      - offsets : numpy array of same shape (float)\n    \"\"\"\n    # Ensure arrays\n    distances = np.asarray(distances, dtype=float)\n    arc_lengths = np.asarray(arc_lengths, dtype=float)\n    processing_rates = np.asarray(processing_rates, dtype=float)\n    queue_lengths = np.asarray(queue_lengths, dtype=float)\n    \n    # Shape check\n    if not (distances.shape == arc_lengths.shape == processing_rates.shape == queue_lengths.shape):\n        raise ValueError(\"All inputs must have the same shape\")\n    \n    # Detect padded/absent neighbours (all-zero feature rows)\n    padded = (distances == 0) & (arc_lengths == 0) & (processing_rates == 0) & (queue_lengths == 0)\n    valid = ~padded\n    offsets = np.zeros_like(distances, dtype=float)\n    \n    if not np.any(valid):\n        return offsets  # all padded -> zero offsets\n    \n    eps = 1e-8\n    \n    # Helper to compute normalized (0..1) with robust min/max over valid entries\n    def norm_positive_better(x):\n        xv = x[valid]\n        mn = np.min(xv)\n        mx = np.max(xv)\n        if mx - mn < eps:\n            return np.ones_like(x) * 0.5  # neutral when no variation\n        out = np.zeros_like(x, dtype=float)\n        out[valid] = (x[valid] - mn) / (mx - mn + eps)\n        return out\n    \n    def norm_negative_better(x):\n        # smaller values are better -> invert normalized positive-better\n        n = norm_positive_better(x)\n        return 1.0 - n\n    \n    # Compute normalized feature scores in [0,1], where higher is better\n    # - queue: smaller is better (strong effect)\n    queue_score = norm_negative_better(queue_lengths)\n    # - arc: smaller arc_length closer to destination -> better\n    arc_score = norm_negative_better(arc_lengths)\n    # - processing rate: higher is better\n    proc_score = norm_positive_better(processing_rates)\n    # - distance: smaller distance reduces propagation delay -> better (weaker effect)\n    dist_score = norm_negative_better(distances)\n    \n    # Weights (sum to 1) emphasizing queue, then arc, proc, dist\n    w_queue = 0.50\n    w_arc = 0.25\n    w_proc = 0.15\n    w_dist = 0.10\n    \n    # Combined score only for valid entries\n    combined = np.zeros_like(distances, dtype=float)\n    combined[valid] = (w_queue * queue_score[valid]\n                       + w_arc * arc_score[valid]\n                       + w_proc * proc_score[valid]\n                       + w_dist * dist_score[valid])\n    \n    # Center combined scores across valid neighbours to create relative preference\n    mean_valid = np.mean(combined[valid])\n    rel_score = np.zeros_like(combined)\n    rel_score[valid] = combined[valid] - mean_valid\n    \n    # Scale to modest offsets so we refine but don't overpower the agent Q-values\n    scale = 0.20  # typical offset magnitude (~[-0.2,0.2])\n    offsets[valid] = rel_score[valid] * scale\n    \n    # Extra nonlinear penalty for very large queues (to avoid drops) using squared term\n    # Determine a soft queue capacity baseline from observed valid queues\n    q_valid = queue_lengths[valid]\n    q_baseline = max(1.0, np.percentile(q_valid, 90))  # aggressive if queue near its 90th percentile\n    extra_penalty = np.zeros_like(offsets)\n    extra_penalty[valid] = -0.15 * ((q_valid / (q_baseline + eps)) ** 2)\n    # Apply penalty but keep offsets within reasonable bounds\n    offsets[valid] += extra_penalty[valid]\n    \n    # Clamp offsets to a safe range\n    np.clip(offsets, -0.3, 0.3, out=offsets)\n    \n    # Ensure padded entries remain zero (neutral); Q-agent should be -inf for them anyway\n    offsets[padded] = 0.0\n    \n    return offsets",
          "objective": 1.5035,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.6130308463407801,
               "avg_dropped_ratio": 0.0783132530120482
          }
     },
     {
          "algorithm": "Compute a small additive offset as a normalized linear combination of proximity (inverse arc length), processing speed, inverse distance (lower propagation delay), and a strong negative penalty for queue occupancy, clipped to a modest range so it refines but does not overpower learned Q-values.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    distances = np.asarray(distances, dtype=float)\n    arc_lengths = np.asarray(arc_lengths, dtype=float)\n    processing_rates = np.asarray(processing_rates, dtype=float)\n    queue_lengths = np.asarray(queue_lengths, dtype=float)\n\n    # Ensure shape consistency\n    if distances.shape != arc_lengths.shape or distances.shape != processing_rates.shape or distances.shape != queue_lengths.shape:\n        raise ValueError(\"All inputs must have the same shape.\")\n\n    # Identify fully zero-padded (absent) neighbours\n    mask_invalid = (distances == 0) & (arc_lengths == 0) & (processing_rates == 0) & (queue_lengths == 0)\n\n    eps = 1e-8\n\n    def minmax_norm(x):\n        mn = np.min(x)\n        mx = np.max(x)\n        if mx - mn < eps:\n            return np.zeros_like(x, dtype=float)\n        return (x - mn) / (mx - mn)\n\n    # Normalizations (higher means \"better\" for processing_rate, worse for arc & distance & queue)\n    norm_proc = minmax_norm(processing_rates)            # higher is better\n    norm_arc = minmax_norm(arc_lengths)                 # higher arc = farther from dest (worse)\n    norm_dist = minmax_norm(distances)                  # higher distance = larger delay (worse)\n    norm_queue = minmax_norm(queue_lengths)             # higher queue = worse\n\n    # Weights chosen to keep offsets small relative to Q-value scale observed (~[-0.5,0.5])\n    w_arc = 0.06      # reward shorter arc (use 1 - norm_arc)\n    w_proc = 0.05     # reward higher processing rate\n    w_dist = 0.02     # small reward for nearer neighbor (lower propagation delay)\n    w_queue = 0.12    # penalize higher queue lengths (strongest term)\n\n    # Compose offset: positive is better for selection\n    offsets = (w_arc * (1.0 - norm_arc)\n               + w_proc * norm_proc\n               + w_dist * (1.0 - norm_dist)\n               - w_queue * norm_queue)\n\n    # Additional non-linear boost: strongly discourage very congested nodes\n    # (small extra penalty for high normalized queue to increase sensitivity)\n    extra_penalty = 0.04 * np.tanh(3.0 * norm_queue)\n    offsets = offsets - extra_penalty\n\n    # Clip to small range so agent's Q-values remain primary driver\n    offsets = np.clip(offsets, -0.15, 0.15)\n\n    # Push fully-zero (absent) neighbours to a large negative offset to avoid selection\n    if np.any(mask_invalid):\n        offsets = offsets.copy()\n        offsets[mask_invalid] = -1.0\n\n    return offsets",
          "objective": 1.4845,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.6188650450311571,
               "avg_dropped_ratio": 0.08132530120481928
          }
     },
     {
          "algorithm": "Combine normalized, bounded feature scores (favoring low arc_length and distance, high processing_rate, and penalizing high queue_length and queue-to-processing ratio) with small weights to produce clipped offsets that gently adjust agent Q-values.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    distances = np.asarray(distances, dtype=float)\n    arc_lengths = np.asarray(arc_lengths, dtype=float)\n    processing_rates = np.asarray(processing_rates, dtype=float)\n    queue_lengths = np.asarray(queue_lengths, dtype=float)\n\n    eps = 1e-8\n\n    def minmax_norm(x):\n        x_min = np.nanmin(x)\n        x_max = np.nanmax(x)\n        rng = x_max - x_min\n        if rng < eps:\n            return np.zeros_like(x)\n        return (x - x_min) / (rng + eps)\n\n    # Normalize features to [0,1]\n    n_dist = minmax_norm(distances)\n    n_arc = minmax_norm(arc_lengths)\n    n_proc = minmax_norm(processing_rates)\n    n_queue = minmax_norm(queue_lengths)\n\n    # Lower distance/arc is better => invert normalized score\n    score_dist = 1.0 - n_dist\n    score_arc = 1.0 - n_arc\n    score_proc = n_proc\n\n    # Utilization-like proxy (queue relative to processing rate)\n    util = queue_lengths / (processing_rates + 1.0)  # +1 to keep scale reasonable\n    n_util = minmax_norm(util)\n\n    # Weights chosen to be small so offsets refine but do not overpower Q-values\n    w_arc = 0.06\n    w_proc = 0.05\n    w_dist = 0.04\n    w_queue = 0.12  # penalty weight for queue occupancy (and utilization)\n    util_factor = 0.5  # extra penalty scaling for util proxy\n\n    offsets = (w_arc * score_arc +\n               w_proc * score_proc +\n               w_dist * score_dist -\n               w_queue * (n_queue + util_factor * n_util))\n\n    # Clip to small range to avoid overpowering learned Q-values\n    offsets = np.clip(offsets, -0.15, 0.15)\n\n    return offsets",
          "objective": 1.4166,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.6495807675347451,
               "avg_dropped_ratio": 0.07981927710843373
          }
     },
     {
          "algorithm": "I compute small, bounded offsets by normalizing features and combining a positive reward for closeness and high service rate with negative penalties for distance and a stronger nonlinear penalty for high queue occupancy, so the offsets nudge but do not overpower the agent Q-values.",
          "code": "import numpy as np\n\ndef compute_offset(distances, arc_lengths, processing_rates, queue_lengths):\n    \"\"\"\n    Inputs: numpy arrays (same shape) for distances, arc_lengths, processing_rates, queue_lengths\n    Output: numpy array 'offsets' of same shape\n    \"\"\"\n    distances = np.asarray(distances, dtype=float)\n    arc_lengths = np.asarray(arc_lengths, dtype=float)\n    processing_rates = np.asarray(processing_rates, dtype=float)\n    queue_lengths = np.asarray(queue_lengths, dtype=float)\n    eps = 1e-8\n\n    # min-max normalization (robust to constant arrays)\n    def minmax(x):\n        xmin = np.min(x)\n        xmax = np.max(x)\n        denom = (xmax - xmin) if (xmax - xmin) > 0 else eps\n        return (x - xmin) / denom\n\n    dn = minmax(distances)         # higher -> worse\n    an = minmax(arc_lengths)       # higher -> farther from dest\n    pn = minmax(processing_rates)  # higher -> better\n    qn = minmax(queue_lengths)     # higher -> worse\n\n    closeness = 1.0 - an           # higher -> closer to destination\n    # stronger-than-linear penalty for heavy queues\n    q_penalty = qn ** 1.8\n\n    # weights chosen to produce small nudges; combined magnitude will be clipped\n    w_queue = 0.08\n    w_arc = 0.06\n    w_proc = 0.05\n    w_dist = 0.03\n\n    offsets = (+ w_arc * closeness\n               + w_proc * pn\n               - w_queue * q_penalty\n               - w_dist * dn)\n\n    # ensure offsets remain modest compared to learned Q-values\n    max_abs_allowed = 0.09\n    max_abs = np.max(np.abs(offsets)) + eps\n    if max_abs > max_abs_allowed:\n        offsets = offsets * (max_abs_allowed / max_abs)\n\n    return offsets",
          "objective": 1.4152,
          "other_inf": null,
          "eval_metrics": {
               "avg_aoi": 0.6384890470794025,
               "avg_dropped_ratio": 0.0963855421686747
          }
     }
]